{"docstore/metadata": {"43978cb8-49a8-4a12-a76c-d50cdb060ebe": {"doc_hash": "a416080d59122c2df4567d2510a642759c9378d5bfe1277a8834e0b64d2af962"}, "84306fc4-20b6-47f4-bfb3-b05836c32cf9": {"doc_hash": "d5eb73ecea4750824790dee467e0e771bf69735f3d425fb1c23ff190f6525df0"}, "ef0972a3-d8e6-4497-a012-b2b31e042571": {"doc_hash": "40876a5122f251d8d0099e96c7e63b14039fc0e2eaa8102346857def434d57e0"}, "b82c908f-a0f7-4bdf-b857-ccee1533431a": {"doc_hash": "81f6dd3bcafa6b76ad5bf034ed470811a9edcf3fcf5e972c41695259b12d53af"}, "26572bf5-57bc-423d-ab22-885056805556": {"doc_hash": "5afe63179f30e51c1d88e0f4313cdf32408df073f5bd9b7cf9d7803f0e0d1373"}, "2cd57556-1644-42bb-b4d4-20c5951cbe4a": {"doc_hash": "1cd0339ce69e00c3ee26dbea14189a90cc61cad202615ad3b929adf9107949e4"}, "59cff5e1-bf86-4a48-9e3a-e8e4be01ab13": {"doc_hash": "2f10077b46153055b777d38b2b2d4a06bf48671313bbee403ad674d7c92fb73c"}, "df972186-b022-409d-9e09-420634671afe": {"doc_hash": "b9d8554d83b2884401cf29805accb4951bcc10e1ff015ac8e61289361eedefd2"}, "2e6e0626-0060-4d7a-b8b9-633524866ebb": {"doc_hash": "d3a0736a37d2ef7c31927d4dbccfb45f85e362d3db04e0552eb92a82087af5fc", "ref_doc_id": "43978cb8-49a8-4a12-a76c-d50cdb060ebe"}, "ede7a182-9e29-4897-9b72-f1a2ba82a423": {"doc_hash": "fc5bc1134af56eaa56845adcdff1458e9099f49aa2572895bfe3a911b334b392", "ref_doc_id": "43978cb8-49a8-4a12-a76c-d50cdb060ebe"}, "0d592a92-29de-4a45-b11c-71b00fc77051": {"doc_hash": "06e59a43b6e4abfeed1c594eb0d2c78ad14009a6b1b211ad4e50687243ff5f49", "ref_doc_id": "43978cb8-49a8-4a12-a76c-d50cdb060ebe"}, "e7077fef-04c3-4115-9943-1e6009924939": {"doc_hash": "a6e1bbb596fd43750bf0c791d1370fe8611e67873cdb610c8be8e45455a0f41d", "ref_doc_id": "84306fc4-20b6-47f4-bfb3-b05836c32cf9"}, "5e06fff4-3e09-447e-bd15-8dbede1ee1b5": {"doc_hash": "be13549ac5916030f2e3dc1cf6677adde55d94fc0ad83d9d2b1a90a2fae55f2b", "ref_doc_id": "84306fc4-20b6-47f4-bfb3-b05836c32cf9"}, "8debc99b-fafc-4191-a7f8-89bf19f2e346": {"doc_hash": "eb4cac449b12f24027609e7a6235deb5c6649b0a21d88adba5ed000ccdc0539d", "ref_doc_id": "84306fc4-20b6-47f4-bfb3-b05836c32cf9"}, "a828a671-68df-4659-8daa-536c914b834a": {"doc_hash": "21b07cceb79eae0582317ea537546bdbb370f2d64a1b1b3a18a0c421494f8909", "ref_doc_id": "ef0972a3-d8e6-4497-a012-b2b31e042571"}, "54a1c31f-72a0-4157-9648-38d4facac79d": {"doc_hash": "fb184de81aac0863f425bc83b6375a4eb7b607b3e22fd870f0a99a98e6f4c02b", "ref_doc_id": "ef0972a3-d8e6-4497-a012-b2b31e042571"}, "002438b1-e0c4-41c2-afb6-28c266a6da0f": {"doc_hash": "942c1656912d08a78e6e9211bc2fb405b9c756077db8fc98090df4f5161b989e", "ref_doc_id": "b82c908f-a0f7-4bdf-b857-ccee1533431a"}, "2e3e9d05-f97b-4d88-aca5-d028bd8602ed": {"doc_hash": "ebbb0bce6ea5b5c7e0f044555914bebaab9a0bb8b6979244989ad5b1bfde9053", "ref_doc_id": "b82c908f-a0f7-4bdf-b857-ccee1533431a"}, "b35cfceb-b1ac-4225-a9f1-5d5c01c6ffad": {"doc_hash": "6cfbf8ae6898db1d74d366a6eb52fe8ac440836993477b206afbd48a86672b80", "ref_doc_id": "26572bf5-57bc-423d-ab22-885056805556"}, "8d286e3f-3679-4020-8fcd-eccc88e16b6c": {"doc_hash": "2d4e37619f328a3c3388365cb69157898922721aa26cff5211976858fafb50c7", "ref_doc_id": "26572bf5-57bc-423d-ab22-885056805556"}, "120673e0-845e-4394-a04d-5c8d8978f0f7": {"doc_hash": "7709233b9067d41f396f7c4e99da8d6f5ecb700e53d1bc7e777c73eea52ead1f", "ref_doc_id": "2cd57556-1644-42bb-b4d4-20c5951cbe4a"}, "a3a514e0-5e13-4061-aa8b-fe10277862aa": {"doc_hash": "e08711ade31ece9d45b2b2480246704eb8de7583b7ba47de9845e674e5cf0efe", "ref_doc_id": "2cd57556-1644-42bb-b4d4-20c5951cbe4a"}, "8dbb9d51-8c0f-494f-bb65-6c5363798fa1": {"doc_hash": "88fb11f6b8615939e7514de518ddab7b4c837ac5e9dfbb9efb9e1bd0c2631aed", "ref_doc_id": "2cd57556-1644-42bb-b4d4-20c5951cbe4a"}, "1852451e-aae0-4572-ad0a-a8e855419c2a": {"doc_hash": "50fda12ddb61b6ae9a342a4e76f9ced0dc24186b4e3bb9a7da6b9d64534e4780", "ref_doc_id": "59cff5e1-bf86-4a48-9e3a-e8e4be01ab13"}, "667617fe-152e-4d91-972e-1100fa27e622": {"doc_hash": "0751f4a08bee59320179d2c38b108be2da07884c2ee0ce4967ddca4b60242e54", "ref_doc_id": "59cff5e1-bf86-4a48-9e3a-e8e4be01ab13"}, "5d08d770-ba81-4308-af28-22f7f6161a88": {"doc_hash": "96440576e7b6b97979616921d04ad7f60434dd982ee8e1c09ac3681afd1cbd9c", "ref_doc_id": "59cff5e1-bf86-4a48-9e3a-e8e4be01ab13"}, "d0f4308b-f5ff-4c69-b739-67c72f5f3209": {"doc_hash": "3bebd86f928c95ad14e25336fe452ffe5cca1e57271ca620f8bbc57ccbe81128", "ref_doc_id": "59cff5e1-bf86-4a48-9e3a-e8e4be01ab13"}, "b97826ca-118c-4aaa-ae1a-049504fee6f6": {"doc_hash": "a6c8d7f84ff5f048ad373e9c191ab27ea87d4dd633a9d0d5f0cca19b266393b0", "ref_doc_id": "df972186-b022-409d-9e09-420634671afe"}, "3ad045db-7f80-4865-8f75-2547415d3556": {"doc_hash": "0f23db44e57d7b6c17633f326938134d37d65356cf522d4ed73ea42efdf047ce", "ref_doc_id": "df972186-b022-409d-9e09-420634671afe"}}, "docstore/data": {"2e6e0626-0060-4d7a-b8b9-633524866ebb": {"__data__": {"id_": "2e6e0626-0060-4d7a-b8b9-633524866ebb", "embedding": null, "metadata": {"page_label": "1", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "43978cb8-49a8-4a12-a76c-d50cdb060ebe", "node_type": "4", "metadata": {"page_label": "1", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "a416080d59122c2df4567d2510a642759c9378d5bfe1277a8834e0b64d2af962", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ede7a182-9e29-4897-9b72-f1a2ba82a423", "node_type": "1", "metadata": {}, "hash": "48d8d6d0b02e76b9c8ba11e6a766179a95d88984b5dfad0a1fb6c5dfc7edf1c1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Proceedings of the 2020 EMNLP (Systems Demonstrations), pages 119\u2013126\nNovember 16-20, 2020.c\u20dd2020 Association for Computational Linguistics\n119\nTextAttack: A Framework for Adversarial Attacks, Data\nAugmentation, and Adversarial Training in NLP\nJohn X. Morris1, Eli Li\ufb02and1, Jin Yong Yoo1, Jake Grigsby1, Di Jin2, Yanjun Qi1\n1 Department of Computer Science, University of Virginia\n2 Computer Science and Arti\ufb01cial Intelligence Laboratory, MIT\n{jm8wx, yq2h}@virginia.edu\nAbstract\nWhile there has been substantial research us-\ning adversarial attacks to analyze NLP mod-\nels, each attack is implemented in its own\ncode repository. It remains challenging to de-\nvelop NLP attacks and utilize them to improve\nmodel performance. This paper introduces\nTextAttack, a Python framework for adver-\nsarial attacks, data augmentation, and adversar-\nial training in NLP.TextAttack builds at-\ntacks from four components: a goal function,\na set of constraints, a transformation, and a\nsearch method. TextAttack\u2019s modular de-\nsign enables researchers to easily construct at-\ntacks from combinations of novel and exist-\ning components. TextAttack provides im-\nplementations of 16 adversarial attacks from\nthe literature and supports a variety of models\nand datasets, including BERT and other trans-\nformers, and all GLUE tasks.TextAttack\nalso includes data augmentation and adver-\nsarial training modules for using components\nof adversarial attacks to improve model ac-\ncuracy and robustness. TextAttack is de-\nmocratizing NLP: anyone can try data aug-\nmentation and adversarial training on any\nmodel or dataset, with just a few lines of\ncode. Code and tutorials are available at\nhttps://github.com/QData/TextAttack.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1699, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ede7a182-9e29-4897-9b72-f1a2ba82a423": {"__data__": {"id_": "ede7a182-9e29-4897-9b72-f1a2ba82a423", "embedding": null, "metadata": {"page_label": "1", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "43978cb8-49a8-4a12-a76c-d50cdb060ebe", "node_type": "4", "metadata": {"page_label": "1", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "a416080d59122c2df4567d2510a642759c9378d5bfe1277a8834e0b64d2af962", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "2e6e0626-0060-4d7a-b8b9-633524866ebb", "node_type": "1", "metadata": {"page_label": "1", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "d3a0736a37d2ef7c31927d4dbccfb45f85e362d3db04e0552eb92a82087af5fc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0d592a92-29de-4a45-b11c-71b00fc77051", "node_type": "1", "metadata": {}, "hash": "5c3d4606ff878c2644084f1bf1ea64907dc5273f69a042c053b18e419e8715a8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "TextAttack is de-\nmocratizing NLP: anyone can try data aug-\nmentation and adversarial training on any\nmodel or dataset, with just a few lines of\ncode. Code and tutorials are available at\nhttps://github.com/QData/TextAttack.\n1 Introduction\nOver the last few years, there has been growing\ninterest in investigating the adversarial robustness\nof NLP models, including new methods for gener-\nating adversarial examples and better approaches\nto defending against these adversaries (Alzantot\net al., 2018; Jin et al., 2019; Kuleshov et al., 2018;\nLi et al., 2019; Gao et al., 2018; Wang et al., 2019;\nEbrahimi et al., 2017; Zang et al., 2020; Pruthi\net al., 2019). It is dif\ufb01cult to compare these attacks\ndirectly and fairly, since they are often evaluated\non different data samples and victim models. Re-\n\u00acOULJLQaO\u00acPeUIecW SeUfRUmaQce b\\ Whe acWRU\u00ac\u00ac \u2192 PRVLWLYe (99%)\n\u00acAdYeUVaULaO\u00acSSRWOeVV SeUfRUmaQce b\\ Whe acWRU \u2192 NeJaWLYe (100%)\nFigure 1: Adversarial example generated usingJin et al.\n(2019)\u2019sTextFooler for a BERT-based sentiment classi\ufb01er.\nSwapping out \u201dperfect\u201d with synonym \u201dspotless\u201d completely\nchanges the model\u2019s prediction, even though the underlying\nmeaning of the text has not changed.\nimplementing previous work as a baseline is often\ntime-consuming and error-prone due to a lack of\nsource code, and precisely replicating results is\ncomplicated by small details left out of the publica-\ntion. These barriers make benchmark comparisons\nhard to trust and severely hinder the development\nof this \ufb01eld.\nTo encourage the development of the adversar-\nial robustness \ufb01eld, we introduceTextAttack,\na Python framework for adversarial attacks, data\naugmentation, and adversarial training in NLP.", "mimetype": "text/plain", "start_char_idx": 1476, "end_char_idx": 3170, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0d592a92-29de-4a45-b11c-71b00fc77051": {"__data__": {"id_": "0d592a92-29de-4a45-b11c-71b00fc77051", "embedding": null, "metadata": {"page_label": "1", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "43978cb8-49a8-4a12-a76c-d50cdb060ebe", "node_type": "4", "metadata": {"page_label": "1", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "a416080d59122c2df4567d2510a642759c9378d5bfe1277a8834e0b64d2af962", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "ede7a182-9e29-4897-9b72-f1a2ba82a423", "node_type": "1", "metadata": {"page_label": "1", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "fc5bc1134af56eaa56845adcdff1458e9099f49aa2572895bfe3a911b334b392", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "These barriers make benchmark comparisons\nhard to trust and severely hinder the development\nof this \ufb01eld.\nTo encourage the development of the adversar-\nial robustness \ufb01eld, we introduceTextAttack,\na Python framework for adversarial attacks, data\naugmentation, and adversarial training in NLP.\nTo unify adversarial attack methods into one\nsystem, we decompose NLP attacks into four com-\nponents: a goal function, a set of constraints, a\ntransformation, and a search method. The attack at-\ntempts to perturb an input text such that the model\noutput ful\ufb01lls the goal function (i.e., indicating\nwhether the attack is successful) and the perturba-\ntion adheres to the set of constraints (e.g., gram-\nmar constraint, semantic similarity constraint). A\nsearch method is used to \ufb01nd a sequence of trans-\nformations that produce a successful adversarial\nexample.\nThis modular design enables us to easily\nassemble attacks from the literature while re-\nusing components that are shared across attacks.\nTextAttack provides clean, readable implemen-\ntations of 16 adversarial attacks from the literature.\nFor the \ufb01rst time, these attacks can be benchmarked,\ncompared, and analyzed in a standardized setting.", "mimetype": "text/plain", "start_char_idx": 2878, "end_char_idx": 4072, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e7077fef-04c3-4115-9943-1e6009924939": {"__data__": {"id_": "e7077fef-04c3-4115-9943-1e6009924939", "embedding": null, "metadata": {"page_label": "2", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "84306fc4-20b6-47f4-bfb3-b05836c32cf9", "node_type": "4", "metadata": {"page_label": "2", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "d5eb73ecea4750824790dee467e0e771bf69735f3d425fb1c23ff190f6525df0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5e06fff4-3e09-447e-bd15-8dbede1ee1b5", "node_type": "1", "metadata": {}, "hash": "50f7d31d0d2cb089e45317a3f87530d1f16df5b58d8c7c944734da11376f7149", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "120\nDeYeORSiQgAWWackV\nCUeaWiQg NeZ AWWacNV\nDaWa AXgPeQWaWiRQ\nBeQchPaUNiQgAWWacNV\nAdYeUVaUiaOTUaiQiQg\n\u00ac CreaWe neZ aWWackV aV a combinaWion of noYel and pre-e[iVWingcomponenWV Te[WAWWack's 82+PUeWUaiQed MRdeOV\nEYalXaWe neZ aWWackV againVW VWandardi]ed modelV\nEYalXaWe aWWackVfrom liWeraWXre againVW VWandardi]ed modelVUVe aWWack recipeVinVWead of reimplemenWing\nAWWackMRdXOe\nReimplemenWaWion ofaWWackV from liWeraWXreCoYerV 16 paperV\nGoal FXncWionConVWrainWVTranVformaWionSearch MeWhod\nGeneraWe adYerVariale[ampleVAdYerVarialE[ampleV UVeU MRdeO\nRepeaW in Wraining loop\nTrain\nTrain\nTextAttack\u0003Training\u0003Pipeline\nUWiOi]iQgAWWackV\nAWWack\u0003ReciSeV\nFoXU ComponenWVof NLP AWWack\u00ac \nAXgPeQWeUMRdXOeGeneraWe\u00ac neZ VampleV UVeU MRdeONeZ DaWaSampleV\nFigure 2: Main features ofTextAttack.\nTextAttack\u2019s design also allows researchers to\neasily construct new attacks from combinations\nof novel and existing components. In just a few\nlines of code, the same search method, transfor-\nmation and constraints used inJin et al.(2019)\u2019s\nTextFooler can be modi\ufb01ed to attack a transla-\ntion model with the goal of changing every word\nin the output.\nTextAttack is directly integrated with Hug-\ngingFace\u2019stransformers and nlp libraries. This\nallows users to test attacks on models and datasets.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1266, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5e06fff4-3e09-447e-bd15-8dbede1ee1b5": {"__data__": {"id_": "5e06fff4-3e09-447e-bd15-8dbede1ee1b5", "embedding": null, "metadata": {"page_label": "2", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "84306fc4-20b6-47f4-bfb3-b05836c32cf9", "node_type": "4", "metadata": {"page_label": "2", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "d5eb73ecea4750824790dee467e0e771bf69735f3d425fb1c23ff190f6525df0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e7077fef-04c3-4115-9943-1e6009924939", "node_type": "1", "metadata": {"page_label": "2", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "a6e1bbb596fd43750bf0c791d1370fe8611e67873cdb610c8be8e45455a0f41d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8debc99b-fafc-4191-a7f8-89bf19f2e346", "node_type": "1", "metadata": {}, "hash": "2af0b1df460413217f5d7569f09e48881bdbd97f40f6ca919f58c2d8f8a0e7ec", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "TextAttack is directly integrated with Hug-\ngingFace\u2019stransformers and nlp libraries. This\nallows users to test attacks on models and datasets.\nTextAttack provides dozens of pre-trained\nmodels (LSTM, CNN, and various transformer-\nbased models) on a variety of popular datasets.\nCurrently TextAttack supports a multitude of\ntasks including summarization, machine transla-\ntion, and all nine tasks from the GLUE benchmark.\nTextAttack also allows users to provide their\nown models and datasets.\nUltimately, the goal of studying adversarial at-\ntacks is to improve model performance and robust-\nness. To that end,TextAttack provides easy-\nto-use tools for data augmentation and adversarial\ntraining. TextAttack\u2019sAugmenter class uses\na transformation and a set of constraints to produce\nnew samples for data augmentation. Attack recipes\nare re-used in a training loop that allows models to\ntrain on adversarial examples. These tools make it\neasier to train accurate and robust models.\nUses forTextAttack include1:\n1All can be done in< 5 lines of code. See A.1.\n\u2022 Benchmarking and comparing NLP attacks\nfrom previous works on standardized models\n& datasets.\n\u2022 Fast development of NLP attack methods by re-\nusing abundant available modules.\n\u2022 Performing ablation studies on individual com-\nponents of proposed attacks and data augmenta-\ntion methods.\n\u2022 Training a model (CNN, LSTM, BERT,\nRoBERTa, etc.) on an augmented dataset.\n\u2022 Adversarial training with attacks from the litera-\nture to improve a model\u2019s robustness.\n2 The TextAttack Framework\nTextAttack aims to implement attacks which,\ngiven an NLP model, \ufb01nd a perturbation of an in-\nput sequence that satis\ufb01es the attack\u2019s goal and\nadheres to certain linguistic constraints. In this\nway, attacking an NLP model can be framed as a\ncombinatorial search problem. The attacker must\nsearch within all potential transformations to \ufb01nd\na sequence of transformations that generate a suc-\ncessful adversarial example.\nEach attack can be constructed from four com-\nponents:\n1. A task-speci\ufb01cgoal functionthat determines\nwhether the attack is successful in terms of\nthe model outputs.", "mimetype": "text/plain", "start_char_idx": 1123, "end_char_idx": 3245, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8debc99b-fafc-4191-a7f8-89bf19f2e346": {"__data__": {"id_": "8debc99b-fafc-4191-a7f8-89bf19f2e346", "embedding": null, "metadata": {"page_label": "2", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "84306fc4-20b6-47f4-bfb3-b05836c32cf9", "node_type": "4", "metadata": {"page_label": "2", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "d5eb73ecea4750824790dee467e0e771bf69735f3d425fb1c23ff190f6525df0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5e06fff4-3e09-447e-bd15-8dbede1ee1b5", "node_type": "1", "metadata": {"page_label": "2", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "be13549ac5916030f2e3dc1cf6677adde55d94fc0ad83d9d2b1a90a2fae55f2b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Each attack can be constructed from four com-\nponents:\n1. A task-speci\ufb01cgoal functionthat determines\nwhether the attack is successful in terms of\nthe model outputs.\nExamples: untargeted classi\ufb01cation, targeted\nclassi\ufb01cation, non-overlapping output, mini-\nmum BLEU score.\n2", "mimetype": "text/plain", "start_char_idx": 3081, "end_char_idx": 3353, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a828a671-68df-4659-8daa-536c914b834a": {"__data__": {"id_": "a828a671-68df-4659-8daa-536c914b834a", "embedding": null, "metadata": {"page_label": "3", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ef0972a3-d8e6-4497-a012-b2b31e042571", "node_type": "4", "metadata": {"page_label": "3", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "40876a5122f251d8d0099e96c7e63b14039fc0e2eaa8102346857def434d57e0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "54a1c31f-72a0-4157-9648-38d4facac79d", "node_type": "1", "metadata": {}, "hash": "68f4b15e21e1f841f846018bfde977137dc9043d65cc825eeaed505864ef5345", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "121\n2. A set ofconstraints that determine if a per-\nturbation is valid with respect to the original\ninput.\nExamples: maximum word embedding dis-\ntance, part-of-speech consistency, grammar\nchecker, minimum sentence encoding cosine\nsimilarity.\n3. A transformation that, given an input, gener-\nates a set of potential perturbations.\nExamples: word embedding word swap, the-\nsaurus word swap, homoglyph character sub-\nstitution.\n4. A search methodthat successively queries\nthe model and selects promising perturbations\nfrom a set of transformations.\nExamples: greedy with word importance rank-\ning, beam search, genetic algorithm.\nSee A.2 for a full explanation of each goal func-\ntion, constraint, transformation, and search method\nthat\u2019s built-in toTextAttack.\n3 Developing NLP Attacks with\nTextAttack\nTextAttack is available as a Python package\ninstalled from PyPI, or via direct download from\nGitHub. TextAttack is also available for use\nthrough our demo web app, displayed in Figure3.\nPython users can test attacks by creating and\nmanipulating Attack objects. The command-line\nAPI offerstextattack attack, which allows\nusers to specify attacks from their four components\nor from a single attack recipe and test them on\ndifferent models and datasets.\nTextAttack supports several different output\nformats for attack results:\n\u2022 Printing results to stdout.\n\u2022 Printing to a text \ufb01le or CSV .\n\u2022 Printing attack results to an HTML table.\n\u2022 Writing a table of attack results to a visualization\nserver, like Visdom or Weights & Biases.\n3.1 Benchmarking Existing Attacks with\nAttack Recipes\nTextAttack\u2019s modular design allows us to\nimplement many different attacks from past work\nin a shared framework, often by adding only one\nor two new components. Table1 categorizes 16\nattacks based on their goal functions, constraints,\ntransformations and search methods.\nAll of these attacks are implemented as \u201dat-\ntack recipes\u201d inTextAttack and can be bench-\nmarked with just a single command. See A.3\nFigure 3: Screenshot ofTextAttack\u2019s web interface run-\nning the TextBugger black-box attack (Li et al., 2019).\nfor a comparison between papers\u2019 reported at-\ntack results and the results achieved by running\nTextAttack.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2202, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "54a1c31f-72a0-4157-9648-38d4facac79d": {"__data__": {"id_": "54a1c31f-72a0-4157-9648-38d4facac79d", "embedding": null, "metadata": {"page_label": "3", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ef0972a3-d8e6-4497-a012-b2b31e042571", "node_type": "4", "metadata": {"page_label": "3", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "40876a5122f251d8d0099e96c7e63b14039fc0e2eaa8102346857def434d57e0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a828a671-68df-4659-8daa-536c914b834a", "node_type": "1", "metadata": {"page_label": "3", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "21b07cceb79eae0582317ea537546bdbb370f2d64a1b1b3a18a0c421494f8909", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "See A.3\nFigure 3: Screenshot ofTextAttack\u2019s web interface run-\nning the TextBugger black-box attack (Li et al., 2019).\nfor a comparison between papers\u2019 reported at-\ntack results and the results achieved by running\nTextAttack.\n3.2 Creating New Attacks by Combining\nNovel and Existing Components\nAs is clear from Table1, many components are\nshared between NLP attacks. New attacks often re-\nuse components from past work, adding one or two\nnovel pieces.TextAttack allows researchers to\nfocus on the generation of new components rather\nthan replicating past results. For example,Jin et al.\n(2019) introducedTextFooler as a method for\nattacking classi\ufb01cation and entailment models. If\na researcher wished to experiment with applying\nTextFooler\u2019s search method, transformations,\nand constraints to attack translation models, all they\nneed is to implement a translation goal function in\nTextAttack. They would then be able to plug\nin this goal function to create a novel attack that\ncould be used to analyze translation models.\n3.3 Evaluating Attacks onTextAttack\u2019s\nPre-Trained Models\nAs of the date of this submission,TextAttack\nprovides users with 82 pre-trained models, includ-\ning word-level LSTM, word-level CNN, BERT, and\nother transformer based models pre-trained on var-\nious datasets provided by HuggingFacenlp. Since\nTextAttack is integrated with thenlp library, it\ncan automatically load the test or validation data\nset for the corresponding pre-trained model. While\nthe literature has mainly focused on classi\ufb01cation\nand entailment,TextAttack\u2019s pretrained mod-\nels enable research on the robustness of models\nacross all GLUE tasks.\n3", "mimetype": "text/plain", "start_char_idx": 1977, "end_char_idx": 3616, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "002438b1-e0c4-41c2-afb6-28c266a6da0f": {"__data__": {"id_": "002438b1-e0c4-41c2-afb6-28c266a6da0f", "embedding": null, "metadata": {"page_label": "4", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b82c908f-a0f7-4bdf-b857-ccee1533431a", "node_type": "4", "metadata": {"page_label": "4", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "81f6dd3bcafa6b76ad5bf034ed470811a9edcf3fcf5e972c41695259b12d53af", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "2e3e9d05-f97b-4d88-aca5-d028bd8602ed", "node_type": "1", "metadata": {}, "hash": "3c054dc5ead03babe93dd6ab8c866b3b2a43dc964d210893fa06f447ed82ce6d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "122\nAttack Recipe Goal\nFunction\nConstraints Transformation Search Method\nbae\n(Garg and\nRamakrishnan, 2020)\nUntargeted\nClassi\ufb01cation\nUSE sentence encoding\ncosine similarity\nBERT Masked Token\nPrediction\nGreedy-WIR\nbert-attack\n(Li et al., 2020)\nUntargeted\nClassi\ufb01cation\nUSE sentence encoding\ncosine similarity,\nMaximum number of\nwords perturbed\nBERT Masked Token\nPrediction (with\nsubword expansion)\nGreedy-WIR\ndeepwordbug\n(Gao et al., 2018)\n{Untargeted,\nTargeted}\nClassi\ufb01cation\nLevenshtein edit\ndistance\n{Character Insertion,\nCharacter Deletion,\nNeighboring Character\nSwap, Character\nSubstitution}*\nGreedy-WIR\nalzantot,\nfast-alzantot\n(Alzantot et al., 2018;\nJia et al., 2019)\nUntargeted\n{Classi\ufb01cation,\nEntailment}\nPercentage of words\nperturbed, Language\nModel perplexity, Word\nembedding distance\nCounter-\ufb01tted word\nembedding swap\nGenetic\nAlgorithm\niga\n(Wang et al., 2019)\nUntargeted\n{Classi\ufb01cation,\nEntailment}\nPercentage of words\nperturbed, Word\nembedding distance\nCounter-\ufb01tted word\nembedding swap\nGenetic\nAlgorithm\ninput-reduction\n(Feng et al., 2018)\nInput\nReduction\nWord deletion Greedy-WIR\nkuleshov\n(Kuleshov et al., 2018)\nUntargeted\nClassi\ufb01cation\nThought vector encoding\ncosine similarity,\nLanguage model\nsimilarity probability\nCounter-\ufb01tted word\nembedding swap\nGreedy word\nswap\nhotflip(word swap)\n(Ebrahimi et al., 2017)\nUntargeted\nClassi\ufb01cation\nWord Embedding Cosine\nSimilarity,\nPart-of-speech match,\nNumber of words\nperturbed\nGradient-Based Word\nSwap\nBeam search\nmorpheus\n(Tan et al.,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1491, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2e3e9d05-f97b-4d88-aca5-d028bd8602ed": {"__data__": {"id_": "2e3e9d05-f97b-4d88-aca5-d028bd8602ed", "embedding": null, "metadata": {"page_label": "4", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b82c908f-a0f7-4bdf-b857-ccee1533431a", "node_type": "4", "metadata": {"page_label": "4", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "81f6dd3bcafa6b76ad5bf034ed470811a9edcf3fcf5e972c41695259b12d53af", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "002438b1-e0c4-41c2-afb6-28c266a6da0f", "node_type": "1", "metadata": {"page_label": "4", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "942c1656912d08a78e6e9211bc2fb405b9c756077db8fc98090df4f5161b989e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": ", 2017)\nUntargeted\nClassi\ufb01cation\nWord Embedding Cosine\nSimilarity,\nPart-of-speech match,\nNumber of words\nperturbed\nGradient-Based Word\nSwap\nBeam search\nmorpheus\n(Tan et al., 2020)\nMinimum\nBLEU Score\nIn\ufb02ection Word Swap Greedy search\npruthi\n(Pruthi et al., 2019)\nUntargeted\nClassi\ufb01cation\nMinimum word length,\nMaximum number of\nwords perturbed\n{Neighboring Character\nSwap, Character\nDeletion, Character\nInsertion,\nKeyboard-Based\nCharacter Swap}*\nGreedy search\npso\n(Zang et al., 2020)\nUntargeted\nClassi\ufb01cation\nHowNet Word Swap Particle Swarm\nOptimization\npwws\n(Ren et al., 2019)\nUntargeted\nClassi\ufb01cation\nWordNet-based\nsynonym swap\nGreedy-WIR\n(saliency)\nseq2sick\n(black-box)\n(Cheng et al., 2018)\nNon-\noverlapping\noutput\nCounter-\ufb01tted word\nembedding swap\nGreedy-WIR\ntextbugger\n(black-box)\n(Li et al., 2019)\nUntargeted\nClassi\ufb01cation\nUSE sentence encoding\ncosine similarity\n{Character Insertion,\nCharacter Deletion,\nNeighboring Character\nSwap, Character\nSubstitution}*\nGreedy-WIR\ntextfooler\n(Jin et al., 2019)\nUntargeted\n{Classi\ufb01cation,\nEntailment}\nWord Embedding\nDistance, Part-of-speech\nmatch, USE sentence\nencoding cosine\nsimilarity\nCounter-\ufb01tted word\nembedding swap\nGreedy-WIR\nTable 1: TextAttack attack recipes categorized within our framework: search method, transformation, goal function,\nconstraints. All attack recipes include an additional constraint which disallows the replacement of stopwords. Greedy search\nwith Word Importance Ranking is abbreviated as Greedy-WIR.\n* indicates a combination of multiple transformations\n4", "mimetype": "text/plain", "start_char_idx": 1318, "end_char_idx": 2846, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b35cfceb-b1ac-4225-a9f1-5d5c01c6ffad": {"__data__": {"id_": "b35cfceb-b1ac-4225-a9f1-5d5c01c6ffad", "embedding": null, "metadata": {"page_label": "5", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "26572bf5-57bc-423d-ab22-885056805556", "node_type": "4", "metadata": {"page_label": "5", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "5afe63179f30e51c1d88e0f4313cdf32408df073f5bd9b7cf9d7803f0e0d1373", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8d286e3f-3679-4020-8fcd-eccc88e16b6c", "node_type": "1", "metadata": {}, "hash": "016041831ae71ee9f31026d1b2d4e44343c2a33dee9c2a01545cc2f8064840e5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "123\n4 Utilizing TextAttack to Improve\nNLP Models\n4.1 Evaluating Robustness of Custom Models\nTextAttack is model-agnostic - meaning it\ncan run attacks on models implemented in any deep\nlearning framework. Model objects must be able\nto take a string (or list of strings) and return an\noutput that can be processed by the goal function.\nFor example, machine translation models take a list\nof strings as input and produce a list of strings as\noutput. Classi\ufb01cation and entailment models return\nan array of scores. As long as the user\u2019s model\nmeets this speci\ufb01cation, the model is \ufb01t to use with\nTextAttack.\n4.2 Model Training\nTextAttack users can train standard LSTM,\nCNN, and transformer based models, or a user-\ncustomized model on any dataset from thenlp li-\nbrary using thetextattack train command.\nJust like pre-trained models, user-trained models\nare compatible with commands liketextattack\nattack and textattack eval.\n4.3 Data Augmentation\nWhile searching for adversarial examples,\nTextAttack\u2019s transformations generate pertur-\nbations of the input text, and apply constraints to\nverify their validity. These tools can be reused to\ndramatically expand the training dataset by intro-\nducing perturbed versions of existing samples. The\ntextattack augment command gives users\naccess to a number of pre-packaged recipes for\naugmenting their dataset. This is a stand-alone\nfeature that can be used with any model or train-\ning framework. When usingTextAttack\u2019s mod-\nels and training pipeline,textattack train\n--augment automatically expands the dataset be-\nfore training begins. Users can specify the fraction\nof each input that should be modi\ufb01ed and how\nmany additional versions of each example to create.\nThis makes it easy to use existing augmentation\nrecipes on different models and datasets, and is a\ngreat way to benchmark new techniques.\nFigure 4 shows empirical results we obtained us-\ning TextAttack\u2019s augmentation. Augmentation\nwith TextAttack immediately improves the per-\nformance of aWordCNN model on small datasets.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2027, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8d286e3f-3679-4020-8fcd-eccc88e16b6c": {"__data__": {"id_": "8d286e3f-3679-4020-8fcd-eccc88e16b6c", "embedding": null, "metadata": {"page_label": "5", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "26572bf5-57bc-423d-ab22-885056805556", "node_type": "4", "metadata": {"page_label": "5", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "5afe63179f30e51c1d88e0f4313cdf32408df073f5bd9b7cf9d7803f0e0d1373", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b35cfceb-b1ac-4225-a9f1-5d5c01c6ffad", "node_type": "1", "metadata": {"page_label": "5", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "6cfbf8ae6898db1d74d366a6eb52fe8ac440836993477b206afbd48a86672b80", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Figure 4 shows empirical results we obtained us-\ning TextAttack\u2019s augmentation. Augmentation\nwith TextAttack immediately improves the per-\nformance of aWordCNN model on small datasets.\n4.4 Adversarial Training\nWith textattack train --attack, at-\ntack recipes can be used to create new training\nFigure 4: Performance of the built-inWordCNN model on the\nrotten tomatoes dataset with increasing training set size.\nData augmentation recipes like EasyDataAugmenter\n(EDA, (Wei and Zou, 2019)) andEmbedding are most help-\nful when working with very few samples. Shaded regions\nrepresent 95% con\ufb01dence intervals overN =5 runs.\nsets of adversarial examples. After training for a\nnumber of epochs on the clean training set, the at-\ntack generates an adversarial version of each input.\nThis perturbed version of the dataset is substituted\nfor the original, and is periodically regenerated ac-\ncording to the model\u2019s current weaknesses. The\nresulting model can be signi\ufb01cantly more robust\nagainst the attack used during training. Table2\nshows the accuracy of a standard LSTM classi\ufb01er\nwith and without adversarial training against differ-\nent attack recipes implemented inTextAttack.\n5 TextAttack Under the Hood\nTextAttack is optimized under-the-hood to\nmake implementing and running adversarial attacks\nsimple and fast.\nAttackedText. A common problem with im-\nplementations of NLP attacks is that the original\ntext is discarded after tokenization; thus, the trans-\nformation is performed on the tokenized version\nof the text. This causes issues with capitalization\nand word segmentation. Sometimes attacks swap a\npiece of a word for a complete word (for example,\ntransforming \u2018\u2018aren\u2019t\" into \u2018\u2018aren\u2019too\").\nTo solve this problem, TextAttack stores\neach input as aAttackedText object which\ncontains the original text and helper meth-\nods for transforming the text while retaining\ntokenization. Instead of strings or tensors,\n5", "mimetype": "text/plain", "start_char_idx": 1843, "end_char_idx": 3755, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "120673e0-845e-4394-a04d-5c8d8978f0f7": {"__data__": {"id_": "120673e0-845e-4394-a04d-5c8d8978f0f7", "embedding": null, "metadata": {"page_label": "6", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2cd57556-1644-42bb-b4d4-20c5951cbe4a", "node_type": "4", "metadata": {"page_label": "6", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "1cd0339ce69e00c3ee26dbea14189a90cc61cad202615ad3b929adf9107949e4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a3a514e0-5e13-4061-aa8b-fe10277862aa", "node_type": "1", "metadata": {}, "hash": "52b72cd5901782fe9c6b67de76efcbc28e3ddf49f181fa51884f71114b61a954", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "124\nAttacked By\nTrained Against - deepwordbug textfooler pruthi hotflip bae\nbaseline (early stopping) 77.30% 23.46% 2.23% 59.01% 64.57% 25.51%\ndeepwordbug(20 epochs) 76.38% 35.07% 4.78% 57.08% 65.06% 27.63%\ndeepwordbug(75 epochs) 73.16% 44.74% 13.42% 58.28% 66.87% 32.77%\ntextfooler(20 epochs) 61.85% 40.09% 29.63% 52.60% 55.75% 39.36%\nTable 2: The default LSTM model trained on3k samples from thesst2 dataset. The baseline uses early stopping on a clean\ntraining set.deepwordbug and textfooler attacks are used for adversarial training. \u2018Accuracy Under Attack\u2018 on the eval\nset is reported for several different attack types.\nclasses in TextAttack operate primarily on\nAttackedText objects. When words are added,\nswapped, or deleted, an AttackedText can\nmaintain proper punctuation and capitalization.\nThe AttackedText also contains implementa-\ntions for common linguistic functions like splitting\ntext into words, splitting text into sentences, and\npart-of-speech tagging.\nCaching. Search methods frequently encounter\nthe same input at different points in the search.\nIn these cases, it is wise to pre-store values to\navoid unnecessary computation. For each input\nexamined during the attack,TextAttack caches\nits model output, as well as the whether or not\nit passed all of the constraints. For some search\nmethods, this memoization can save a signi\ufb01cant\namount of time.2\n6 Related Work\nWe draw inspiration from theTransformers\nlibrary (Wolf et al., 2019) as an example of a\nwell-designed Natural Language Processing library.\nSome ofTextAttack\u2019s models and tokenizers\nare implemented usingTransformers.\ncleverhans (Papernot et al., 2018) is a library\nfor constructing adversarial examples for computer\nvision models.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1717, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a3a514e0-5e13-4061-aa8b-fe10277862aa": {"__data__": {"id_": "a3a514e0-5e13-4061-aa8b-fe10277862aa", "embedding": null, "metadata": {"page_label": "6", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2cd57556-1644-42bb-b4d4-20c5951cbe4a", "node_type": "4", "metadata": {"page_label": "6", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "1cd0339ce69e00c3ee26dbea14189a90cc61cad202615ad3b929adf9107949e4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "120673e0-845e-4394-a04d-5c8d8978f0f7", "node_type": "1", "metadata": {"page_label": "6", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "7709233b9067d41f396f7c4e99da8d6f5ecb700e53d1bc7e777c73eea52ead1f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8dbb9d51-8c0f-494f-bb65-6c5363798fa1", "node_type": "1", "metadata": {}, "hash": "80ae3bf2afeb7051010e354b8c4b0fe2bcc2002475caafc118dc9802b1519379", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Some ofTextAttack\u2019s models and tokenizers\nare implemented usingTransformers.\ncleverhans (Papernot et al., 2018) is a library\nfor constructing adversarial examples for computer\nvision models. Like cleverhans, we aim to\nprovide methods that generate adversarial exam-\nples across a variety of models and datasets. In\nsome sense,TextAttack strives to be a solution\nlike cleverhans for the NLP community. Like\ncleverhans, attacks inTextAttack all im-\nplement a baseAttack class. However, while\ncleverhans implements many disparate attacks\nin separate modules,TextAttack builds attacks\nfrom a library of shared components.\nThere are some existing open-source libraries re-\nlated to adversarial examples in NLP.Trickster\nproposes a method for attacking NLP models based\non graph search, but lacks the ability to ensure\n2Caching alone speeds up the genetic algorithm ofAlzantot\net al.(2018) by a factor of 5.\nthat generated examples satisfy a given constraint\n(Kulynych et al., 2018). TEAPOT is a library for\nevaluating adversarial perturbations on text, but\nonly supports the application of ngram-based com-\nparisons for evaluating attacks on machine transla-\ntion models (Michel et al., 2019). Most recently,\nAllenNLP Interpret includes functionality\nfor running adversarial attacks on NLP models, but\nis intended only for the purpose of interpretability,\nand only supports attacks via input-reduction or\ngreedy gradient-based word swap (Wallace et al.,\n2019). TextAttack has a broader scope than any\nof these libraries: it is designed to be extendable to\nany NLP attack.\n7 Conclusion\nWe presented TextAttack, an open-source\nframework for testing the robustness of NLP mod-\nels. TextAttack de\ufb01nes an attack in four mod-\nules: a goal function, a list of constraints, a trans-\nformation, and a search method. This allows us to\ncompose attacks from previous work from these\nmodules and compare them in a shared environ-\nment. These attacks can be reused for data aug-\nmentation and adversarial training.", "mimetype": "text/plain", "start_char_idx": 1527, "end_char_idx": 3522, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8dbb9d51-8c0f-494f-bb65-6c5363798fa1": {"__data__": {"id_": "8dbb9d51-8c0f-494f-bb65-6c5363798fa1", "embedding": null, "metadata": {"page_label": "6", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2cd57556-1644-42bb-b4d4-20c5951cbe4a", "node_type": "4", "metadata": {"page_label": "6", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "1cd0339ce69e00c3ee26dbea14189a90cc61cad202615ad3b929adf9107949e4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a3a514e0-5e13-4061-aa8b-fe10277862aa", "node_type": "1", "metadata": {"page_label": "6", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "e08711ade31ece9d45b2b2480246704eb8de7583b7ba47de9845e674e5cf0efe", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This allows us to\ncompose attacks from previous work from these\nmodules and compare them in a shared environ-\nment. These attacks can be reused for data aug-\nmentation and adversarial training. As new at-\ntacks are developed, we will add their components\nto TextAttack. We hopeTextAttack helps\nlower the barrier to entry for research into robust-\nness and data augmentation in NLP.3\n8 Acknowledgements\nThe authors would like to thank everyone who\nhas contributed to makeTextAttack a reality:\nHanyu Liu, Kevin Ivey, Bill Zhang, and Alan\nZheng, to name a few. Thanks to the IGA creators\n(Wang et al., 2019) for contributing an implementa-\ntion of their algorithm to our framework. Thanks to\nthe folks at HuggingFace for creating such easy-to-\nuse software; without them,TextAttack would\nnot be what it is today.\n3For more information, an appendix is available online\nhere.\n6", "mimetype": "text/plain", "start_char_idx": 3329, "end_char_idx": 4201, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1852451e-aae0-4572-ad0a-a8e855419c2a": {"__data__": {"id_": "1852451e-aae0-4572-ad0a-a8e855419c2a", "embedding": null, "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "59cff5e1-bf86-4a48-9e3a-e8e4be01ab13", "node_type": "4", "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "2f10077b46153055b777d38b2b2d4a06bf48671313bbee403ad674d7c92fb73c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "667617fe-152e-4d91-972e-1100fa27e622", "node_type": "1", "metadata": {}, "hash": "b567a7ac884deab6ac56a6bdb8a02aa1f8d2435cfe0099bd9cc08263a337bbaf", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "125\nReferences\nAbhaya Agarwal and Alon Lavie. 2008. Meteor,\nm-bleu and m-ter: Evaluation metrics for high-\ncorrelation with human rankings of machine trans-\nlation output. InWMT@ACL.\nMoustafa Alzantot, Yash Sharma, Ahmed Elgohary,\nBo-Jhang Ho, Mani B. Srivastava, and Kai-Wei\nChang. 2018. Generating natural language adversar-\nial examples.ArXiv, abs/1804.07998.\nDaniel Matthew Cer, Yinfei Yang, Sheng yi Kong,\nNan Hua, Nicole Limtiaco, Rhomni St. John, Noah\nConstant, Mario Guajardo-Cespedes, Steve Yuan,\nChris Tar, Yun-Hsuan Sung, Brian Strope, and Ray\nKurzweil. 2018. Universal sentence encoder.ArXiv,\nabs/1803.11175.\nMinhao Cheng, Jinfeng Yi, Pin-Yu Chen, Huan Zhang,\nand Cho-Jui Hsieh. 2018.Seq2sick: Evaluating the\nrobustness of sequence-to-sequence models with ad-\nversarial examples.\nAlexis Conneau, Douwe Kiela, Holger Schwenk, Lo\u00a8\u0131c\nBarrault, and Antoine Bordes. 2017. Supervised\nlearning of universal sentence representations from\nnatural language inference data. InEMNLP.\nZhendong Dong, Qiang Dong, and Changling Hao.\n2006. Hownet and the computation of meaning.\nJavid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing\nDou. 2017. Hot\ufb02ip: White-box adversarial exam-\nples for text classi\ufb01cation. InACL.\nShi Feng, Eric Wallace, Alvin Grissom II, Mohit Iyyer,\nPedro Rodriguez, and Jordan Boyd-Graber. 2018.\nPathologies of neural models make interpretations\ndif\ufb01cult.\nJi Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun\nQi. 2018.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1431, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "667617fe-152e-4d91-972e-1100fa27e622": {"__data__": {"id_": "667617fe-152e-4d91-972e-1100fa27e622", "embedding": null, "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "59cff5e1-bf86-4a48-9e3a-e8e4be01ab13", "node_type": "4", "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "2f10077b46153055b777d38b2b2d4a06bf48671313bbee403ad674d7c92fb73c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1852451e-aae0-4572-ad0a-a8e855419c2a", "node_type": "1", "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "50fda12ddb61b6ae9a342a4e76f9ced0dc24186b4e3bb9a7da6b9d64534e4780", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5d08d770-ba81-4308-af28-22f7f6161a88", "node_type": "1", "metadata": {}, "hash": "eeef3b42a5f214e02f8e4d7dca3f6abe4b624843b8e3079fdfd701dfd1c205fa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2018.\nPathologies of neural models make interpretations\ndif\ufb01cult.\nJi Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun\nQi. 2018. Black-box generation of adversarial text\nsequences to evade deep learning classi\ufb01ers.2018\nIEEE Security and Privacy Workshops (SPW), pages\n50\u201356.\nSiddhant Garg and Goutham Ramakrishnan. 2020.\nBae: Bert-based adversarial examples for text clas-\nsi\ufb01cation.\nAri Holtzman, Jan Buys, Maxwell Forbes, Antoine\nBosselut, David Golub, and Yejin Choi. 2018.\nLearning to write with cooperative discriminators.\nIn Proceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers), pages 1638\u20131649, Melbourne, Aus-\ntralia. Association for Computational Linguistics.\nRobin Jia and Percy Liang. 2017.Adversarial exam-\nples for evaluating reading comprehension systems.\nIn Proceedings of the 2017 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n2021\u20132031, Copenhagen, Denmark. Association for\nComputational Linguistics.\nRobin Jia, Aditi Raghunathan, Kerem G \u00a8oksel, and\nPercy Liang. 2019. Certi\ufb01ed robustness to adversar-\nial word substitutions. InEMNLP/IJCNLP.\nDi Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter\nSzolovits. 2019. Is bert really robust? natural lan-\nguage attack on text classi\ufb01cation and entailment.\nArXiv, abs/1907.11932.\nRafal J\u00b4ozefowicz, Oriol Vinyals, Mike Schuster, Noam\nShazeer, and Yonghui Wu. 2016. Exploring the lim-\nits of language modeling.ArXiv, abs/1602.02410.\nJames Kennedy and Russell Eberhart. 1995. Particle\nswarm optimization. In Proceedings of ICNN\u201995-\nInternational Conference on Neural Networks, vol-\nume 4, pages 1942\u20131948.", "mimetype": "text/plain", "start_char_idx": 1304, "end_char_idx": 2949, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5d08d770-ba81-4308-af28-22f7f6161a88": {"__data__": {"id_": "5d08d770-ba81-4308-af28-22f7f6161a88", "embedding": null, "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "59cff5e1-bf86-4a48-9e3a-e8e4be01ab13", "node_type": "4", "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "2f10077b46153055b777d38b2b2d4a06bf48671313bbee403ad674d7c92fb73c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "667617fe-152e-4d91-972e-1100fa27e622", "node_type": "1", "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "0751f4a08bee59320179d2c38b108be2da07884c2ee0ce4967ddca4b60242e54", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d0f4308b-f5ff-4c69-b739-67c72f5f3209", "node_type": "1", "metadata": {}, "hash": "b2dee800fa3541e662829d23c44a55d7eac52e79f18d32cc16fd3ffa7740fa64", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "James Kennedy and Russell Eberhart. 1995. Particle\nswarm optimization. In Proceedings of ICNN\u201995-\nInternational Conference on Neural Networks, vol-\nume 4, pages 1942\u20131948. IEEE.\nRyan Kiros, Yukun Zhu, Ruslan Salakhutdinov,\nRichard S. Zemel, Raquel Urtasun, Antonio Tor-\nralba, and Sanja Fidler. 2015. Skip-thought vectors.\nArXiv, abs/1506.06726.\nV olodymyr Kuleshov, Shantanu Thakoor, Tingfung\nLau, and Stefano Ermon. 2018. Adversarial exam-\nples for natural language classi\ufb01cation problems.\nBogdan Kulynych, Jamie Hayes, Nikita Samarin, and\nCarmela Troncoso. 2018.Evading classi\ufb01ers in dis-\ncrete domains with provable optimality guarantees.\nCoRR, abs/1810.10939.\nJinfeng Li, Shouling Ji, Tianyu Du, Bo Li, and Ting\nWang. 2019. Textbugger: Generating adversar-\nial text against real-world applications. ArXiv,\nabs/1812.05271.\nLinyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue,\nand Xipeng Qiu. 2020.Bert-attack: Adversarial at-\ntack against bert using bert.\nPaul Michel, Xian Li, Graham Neubig, and\nJuan Miguel Pino. 2019. On evaluation of ad-\nversarial perturbations for sequence-to-sequence\nmodels. CoRR, abs/1903.06620.\nGeorge Armitage Miller, Richard Beckwith, Christiane\nFellbaum, Derek Gross, and Katherine J. Miller.\n1990. Introduction to wordnet: An on-line lexical\ndatabase. International Journal of Lexicography,\n3:235\u2013244.", "mimetype": "text/plain", "start_char_idx": 2778, "end_char_idx": 4111, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d0f4308b-f5ff-4c69-b739-67c72f5f3209": {"__data__": {"id_": "d0f4308b-f5ff-4c69-b739-67c72f5f3209", "embedding": null, "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "59cff5e1-bf86-4a48-9e3a-e8e4be01ab13", "node_type": "4", "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "2f10077b46153055b777d38b2b2d4a06bf48671313bbee403ad674d7c92fb73c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5d08d770-ba81-4308-af28-22f7f6161a88", "node_type": "1", "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "96440576e7b6b97979616921d04ad7f60434dd982ee8e1c09ac3681afd1cbd9c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "George Armitage Miller, Richard Beckwith, Christiane\nFellbaum, Derek Gross, and Katherine J. Miller.\n1990. Introduction to wordnet: An on-line lexical\ndatabase. International Journal of Lexicography,\n3:235\u2013244.\nNikola Mrk\u02c7si\u00b4c, Diarmuid O S\u00b4eaghdha, Blaise Thom-\nson, Milica Ga \u02c7si\u00b4c, Lina Rojas-Barahona, Pei-\nHao Su, David Vandyke, Tsung-Hsien Wen, and\nSteve Young. 2016. Counter-\ufb01tting word vec-\ntors to linguistic constraints. arXiv preprint\narXiv:1603.00892.\nDaniel Naber et al. 2003.A rule-based style and gram-\nmar checker. Citeseer.\nNicolas Papernot, Fartash Faghri, Nicholas Carlini, Ian\nGoodfellow, Reuben Feinman, Alexey Kurakin, Ci-\nhang Xie, Yash Sharma, Tom Brown, Aurko Roy,\n7", "mimetype": "text/plain", "start_char_idx": 3901, "end_char_idx": 4592, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b97826ca-118c-4aaa-ae1a-049504fee6f6": {"__data__": {"id_": "b97826ca-118c-4aaa-ae1a-049504fee6f6", "embedding": null, "metadata": {"page_label": "8", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "df972186-b022-409d-9e09-420634671afe", "node_type": "4", "metadata": {"page_label": "8", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "b9d8554d83b2884401cf29805accb4951bcc10e1ff015ac8e61289361eedefd2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3ad045db-7f80-4865-8f75-2547415d3556", "node_type": "1", "metadata": {}, "hash": "46160a06f7df04f37b44c5ab0197aa990a8e5282dc842eb2d41b6257223edc75", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "126\nAlexander Matyasko, Vahid Behzadan, Karen Ham-\nbardzumyan, Zhishuai Zhang, Yi-Lin Juang, Zhi Li,\nRyan Sheatsley, Abhibhav Garg, Jonathan Uesato,\nWilli Gierke, Yinpeng Dong, David Berthelot, Paul\nHendricks, Jonas Rauber, and Rujun Long. 2018.\nTechnical report on the cleverhans v2.1.0 adversarial\nexamples library.arXiv preprint arXiv:1610.00768.\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-\nJing Zhu. 2001. Bleu: a method for automatic eval-\nuation of machine translation. InACL.\nMaja Popovic. 2015. chrf: character n-gram f-score for\nautomatic mt evaluation. InWMT@EMNLP.\nDanish Pruthi, Bhuwan Dhingra, and Zachary C. Lip-\nton. 2019. Combating adversarial misspellings with\nrobust word recognition.\nAlec Radford, Jeff Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nNils Reimers and Iryna Gurevych. 2019. Sentence-\nbert: Sentence embeddings using siamese bert-\nnetworks. InProceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing.\nAssociation for Computational Linguistics.\nShuhuai Ren, Yihe Deng, Kun He, and Wanxiang Che.\n2019. Generating natural language adversarial ex-\namples through probability weighted word saliency.\nIn Proceedings of the 57th Annual Meeting of the\nAssociation for Computational Linguistics, pages\n1085\u20131097, Florence, Italy. Association for Compu-\ntational Linguistics.\nSamson Tan, Sha\ufb01q Joty, Min-Yen Kan, and Richard\nSocher. 2020. It\u2019s morphin\u2019 time! Combating\nlinguistic discrimination with in\ufb02ectional perturba-\ntions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1564, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3ad045db-7f80-4865-8f75-2547415d3556": {"__data__": {"id_": "3ad045db-7f80-4865-8f75-2547415d3556", "embedding": null, "metadata": {"page_label": "8", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "df972186-b022-409d-9e09-420634671afe", "node_type": "4", "metadata": {"page_label": "8", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "b9d8554d83b2884401cf29805accb4951bcc10e1ff015ac8e61289361eedefd2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b97826ca-118c-4aaa-ae1a-049504fee6f6", "node_type": "1", "metadata": {"page_label": "8", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}, "hash": "a6c8d7f84ff5f048ad373e9c191ab27ea87d4dd633a9d0d5f0cca19b266393b0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Samson Tan, Sha\ufb01q Joty, Min-Yen Kan, and Richard\nSocher. 2020. It\u2019s morphin\u2019 time! Combating\nlinguistic discrimination with in\ufb02ectional perturba-\ntions. In Proceedings of the 58th Annual Meet-\ning of the Association for Computational Linguistics,\npages 2920\u20132935, Online. Association for Computa-\ntional Linguistics.\nEric Wallace, Jens Tuyls, Junlin Wang, Sanjay Subra-\nmanian, Matthew Gardner, and Sameer Singh. 2019.\nAllennlp interpret: A framework for explaining pre-\ndictions of nlp models.ArXiv, abs/1909.09251.\nXiaosen Wang, Hao Jin, and Kun He. 2019.Natural\nlanguage adversarial attacks and defenses in word\nlevel.\nJason W. Wei and Kai Zou. 2019.EDA: easy data aug-\nmentation techniques for boosting performance on\ntext classi\ufb01cation tasks. CoRR, abs/1901.11196.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R\u2019emi Louf, Morgan Funtow-\nicz, and Jamie Brew. 2019. Transformers: State-of-\nthe-art natural language processing.\nYuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu,\nMeng Zhang, Qun Liu, and Maosong Sun. 2020.\nWord-level textual adversarial attacking as combina-\ntorial optimization. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational\nLinguistics, pages 6066\u20136080, Online. Association\nfor Computational Linguistics.\nTianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q.\nWeinberger, and Yoav Artzi. 2020.Bertscore: Eval-\nuating text generation with bert. In International\nConference on Learning Representations.\n8", "mimetype": "text/plain", "start_char_idx": 1412, "end_char_idx": 2942, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"43978cb8-49a8-4a12-a76c-d50cdb060ebe": {"node_ids": ["2e6e0626-0060-4d7a-b8b9-633524866ebb", "ede7a182-9e29-4897-9b72-f1a2ba82a423", "0d592a92-29de-4a45-b11c-71b00fc77051"], "metadata": {"page_label": "1", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}}, "84306fc4-20b6-47f4-bfb3-b05836c32cf9": {"node_ids": ["e7077fef-04c3-4115-9943-1e6009924939", "5e06fff4-3e09-447e-bd15-8dbede1ee1b5", "8debc99b-fafc-4191-a7f8-89bf19f2e346"], "metadata": {"page_label": "2", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}}, "ef0972a3-d8e6-4497-a012-b2b31e042571": {"node_ids": ["a828a671-68df-4659-8daa-536c914b834a", "54a1c31f-72a0-4157-9648-38d4facac79d"], "metadata": {"page_label": "3", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}}, "b82c908f-a0f7-4bdf-b857-ccee1533431a": {"node_ids": ["002438b1-e0c4-41c2-afb6-28c266a6da0f", "2e3e9d05-f97b-4d88-aca5-d028bd8602ed"], "metadata": {"page_label": "4", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}}, "26572bf5-57bc-423d-ab22-885056805556": {"node_ids": ["b35cfceb-b1ac-4225-a9f1-5d5c01c6ffad", "8d286e3f-3679-4020-8fcd-eccc88e16b6c"], "metadata": {"page_label": "5", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}}, "2cd57556-1644-42bb-b4d4-20c5951cbe4a": {"node_ids": ["120673e0-845e-4394-a04d-5c8d8978f0f7", "a3a514e0-5e13-4061-aa8b-fe10277862aa", "8dbb9d51-8c0f-494f-bb65-6c5363798fa1"], "metadata": {"page_label": "6", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}}, "59cff5e1-bf86-4a48-9e3a-e8e4be01ab13": {"node_ids": ["1852451e-aae0-4572-ad0a-a8e855419c2a", "667617fe-152e-4d91-972e-1100fa27e622", "5d08d770-ba81-4308-af28-22f7f6161a88", "d0f4308b-f5ff-4c69-b739-67c72f5f3209"], "metadata": {"page_label": "7", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}}, "df972186-b022-409d-9e09-420634671afe": {"node_ids": ["b97826ca-118c-4aaa-ae1a-049504fee6f6", "3ad045db-7f80-4865-8f75-2547415d3556"], "metadata": {"page_label": "8", "file_name": "J5.pdf", "file_path": "uploaded_pdfs/J5.pdf", "file_type": "application/pdf", "file_size": 1075503, "creation_date": "2025-04-24", "last_modified_date": "2024-02-15"}}}}